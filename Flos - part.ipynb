{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Input - somewhat reinforcement learning\n",
    "\n",
    "3 inputs\n",
    "1. all train input samples in one array\n",
    "2. all train output samples in one array\n",
    "2. the test input\n",
    "3. the past predictions for this task\n",
    "\n",
    "2 output\n",
    "1. single pixel - value 0-9\n",
    "2. the predicted size of the task\n",
    "\n",
    "\n",
    "SUDO CODE TRAINING: \n",
    "\n",
    "1. get perfect samples for every pixel\n",
    "2. predict every sample pixel 100.000x (e-greedy: first random then with model)\n",
    "3. get discounted rewards for every prediction - (1 point for completed column, 1 point for completed row, 1 point for right pixel value)\n",
    "4. train network on all collected samples\n",
    "5. iterate over 2-4 until convergence ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#tensorflow\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv1D, MaxPooling1D, concatenate, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)  # Set a random seed for reproducibility\n",
    "\n",
    "# utils\n",
    "import utils.file_handling as io\n",
    "from utils import plotting as plt\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\ntf.Tensor(\n[[22. 28.]\n [49. 64.]], shape=(2, 2), dtype=float32)\n"
    }
   ],
   "source": [
    "# tensoflow-gpu test \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-Input-Output-CNN\n",
    "\n",
    "def create_model():\n",
    "    input_X1 = Input(shape=(None, 1))\n",
    "    input_X2 = Input(shape=(None, 1))\n",
    "    input_Y1 = Input(shape=(None, 1))\n",
    "    input_Y2 = Input(shape=(1024, 1))\n",
    "    x_1 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_X1)\n",
    "    x_2 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_X2)\n",
    "    x_sub = Subtract()([x_1, x_2])\n",
    "    x_fin = Conv1D(32, kernel_size=(4), strides=1, padding='same', name='training_task_final_layer')(x_sub)\n",
    "    \n",
    "    y_1 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_Y1)\n",
    "    y_1_pooling = MaxPooling1D(4)(y_1)\n",
    "    #y_1_flatten = Flatten()(y_1_pooling)\n",
    "    y_2 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_Y2)\n",
    "    y_2_pooling = MaxPooling1D(4)(y_2)\n",
    "    #y_2_flatten = Flatten()(y_2_pooling)\n",
    "    y_con = concatenate([y_1_pooling, y_2_pooling])\n",
    "    y_fin = Conv1D(32, kernel_size=(4), strides=1, padding='same', name='test_task_final_layer')(y_con)\n",
    "    \n",
    "    merge = concatenate([x_fin, y_fin])\n",
    "    #flat_layer = Flatten()(merge)\n",
    "\n",
    "    \n",
    "    out_1 = Dense(11, activation='relu')(merge)\n",
    "    out_1 = Dense(128, activation='relu')(out_1)\n",
    "    out_1 = Dense(256, activation='relu')(out_1)\n",
    "    out_1 = Dense(512, activation='relu')(out_1)\n",
    "    out_1 = Dense(1, activation='softmax', name='pixel_predictor')(out_1)\n",
    "\n",
    "    out_2 = Dense(64, activation='relu')(merge)\n",
    "    out_2 = Dense(1, activation='linear', name='shape_predictor')(out_2)\n",
    "    \n",
    "    model = Model(inputs=[input_X1, input_X2, input_Y1, input_Y2], outputs=[out_1, out_2])\n",
    "    \n",
    "    opt = Adam(lr=1e-3, decay=1e-3)\n",
    "    losses = {\n",
    "        \"pixel_predictor\": \"categorical_crossentropy\",\n",
    "        \"shape_predictor\": \"mean_absolute_error\",\n",
    "    }\n",
    "\n",
    "    model.compile(loss=losses, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "#multi_cnn = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_27 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_28 (InputLayer)           [(None, 1024, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_25 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_26 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\nconv1d_39 (Conv1D)              (None, None, 32)     160         input_27[0][0]                   \n__________________________________________________________________________________________________\nconv1d_40 (Conv1D)              (None, 1024, 32)     160         input_28[0][0]                   \n__________________________________________________________________________________________________\nconv1d_37 (Conv1D)              (None, None, 32)     160         input_25[0][0]                   \n__________________________________________________________________________________________________\nconv1d_38 (Conv1D)              (None, None, 32)     160         input_26[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_4 (MaxPooling1D)  (None, None, 32)     0           conv1d_39[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_5 (MaxPooling1D)  (None, 256, 32)      0           conv1d_40[0][0]                  \n__________________________________________________________________________________________________\nsubtract_8 (Subtract)           (None, None, 32)     0           conv1d_37[0][0]                  \n                                                                 conv1d_38[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_13 (Concatenate)    (None, 256, 64)      0           max_pooling1d_4[0][0]            \n                                                                 max_pooling1d_5[0][0]            \n__________________________________________________________________________________________________\ntraining_task_final_layer (Conv (None, None, 32)     4128        subtract_8[0][0]                 \n__________________________________________________________________________________________________\ntest_task_final_layer (Conv1D)  (None, 256, 32)      8224        concatenate_13[0][0]             \n__________________________________________________________________________________________________\nconcatenate_14 (Concatenate)    (None, 256, 64)      0           training_task_final_layer[0][0]  \n                                                                 test_task_final_layer[0][0]      \n__________________________________________________________________________________________________\ndense_26 (Dense)                (None, 256, 11)      715         concatenate_14[0][0]             \n__________________________________________________________________________________________________\ndense_27 (Dense)                (None, 256, 128)     1536        dense_26[0][0]                   \n__________________________________________________________________________________________________\ndense_28 (Dense)                (None, 256, 256)     33024       dense_27[0][0]                   \n__________________________________________________________________________________________________\ndense_29 (Dense)                (None, 256, 512)     131584      dense_28[0][0]                   \n__________________________________________________________________________________________________\ndense_30 (Dense)                (None, 256, 64)      4160        concatenate_14[0][0]             \n__________________________________________________________________________________________________\npixel_predictor (Dense)         (None, 256, 1)       513         dense_29[0][0]                   \n__________________________________________________________________________________________________\nshape_predictor (Dense)         (None, 256, 1)       65          dense_30[0][0]                   \n==================================================================================================\nTotal params: 184,589\nTrainable params: 184,589\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "multi_cnn = create_model()\n",
    "multi_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([7., 0., 7., 7., 0., 7., 7., 7., 0.])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "training_path = os.getcwd()+'/data/training/'\n",
    "train_data = io.get_tasks(training_path)\n",
    "\n",
    "def preprocess_task(task):\n",
    "    input_1 = [] # all training inputs flattened and concatenated\n",
    "    input_2 = [] # all training outputs flattened and concatenated\n",
    "    input_3 = [] # all test inputs \n",
    "    input_4 = np.array([10 for i in range(32*32)])# Initially None, will be filled with predicted values over time\n",
    "    for sample in task['train']:\n",
    "        input_1 = np.append(input_1, sample['input'])\n",
    "        input_2 = np.append(input_2, sample['output'])\n",
    "    for sample in task['test']:\n",
    "        input_3 = np.append(input_3, sample['input'])\n",
    "    return input_1, input_2, input_3, input_4\n",
    "\n",
    "input_list_1, input_list_2, input_list_3, input_list_4 = [], [], [], []\n",
    "for task in train_data:\n",
    "    input_1, input_2, input_3, input_4 = preprocess_task(task)\n",
    "    input_list_1.append(input_1)\n",
    "    input_list_2.append(input_2)\n",
    "    input_list_3.append(input_3)\n",
    "    input_list_4.append(input_4)\n",
    "input_list_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([9, 9])"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "output_shape = []\n",
    "for task in train_data:\n",
    "    rows = len(task['test'][0]['output'])\n",
    "    cols = len(task['test'][0]['output'][0])\n",
    "    output_shape.append(np.array([rows, cols]))\n",
    "output_shape = np.array(output_shape)\n",
    "iterations_per_task = [np.prod(task) for task in output_shape]\n",
    "output_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([False, False, False, False, False, False, False,  True, False,\n       False, False])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "output_pixel_all_iterations = []\n",
    "for task in train_data:\n",
    "    full_output = np.array(task['test'][0]['output']).flatten()\n",
    "    all_iters_task = []\n",
    "    for i in range(len(full_output)): # number of iterations = number of pixels in test ouput\n",
    "        pixel = full_output[i]\n",
    "        pixel_dummies = np.array([pixel == i for i in range(0, 11)])\n",
    "        all_iters_task.append(pixel_dummies)\n",
    "    output_pixel_all_iterations.append(all_iters_task)\n",
    "output_pixel_all_iterations[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "389"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(output_pixel_all_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_13\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_63 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_64 (InputLayer)           [(None, 1024, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_61 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_62 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\nconv1d_75 (Conv1D)              (None, None, 32)     160         input_63[0][0]                   \n__________________________________________________________________________________________________\nconv1d_76 (Conv1D)              (None, 1024, 32)     160         input_64[0][0]                   \n__________________________________________________________________________________________________\nconv1d_73 (Conv1D)              (None, None, 32)     160         input_61[0][0]                   \n__________________________________________________________________________________________________\nconv1d_74 (Conv1D)              (None, None, 32)     160         input_62[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling1d_22 (MaxPooling1D) (None, None, 32)     0           conv1d_75[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_23 (MaxPooling1D) (None, 512, 32)      0           conv1d_76[0][0]                  \n__________________________________________________________________________________________________\nsubtract_17 (Subtract)          (None, None, 32)     0           conv1d_73[0][0]                  \n                                                                 conv1d_74[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_31 (Concatenate)    (None, 512, 64)      0           max_pooling1d_22[0][0]           \n                                                                 max_pooling1d_23[0][0]           \n__________________________________________________________________________________________________\ntraining_task_final_layer (Conv (None, None, 32)     4128        subtract_17[0][0]                \n__________________________________________________________________________________________________\ntest_task_final_layer (Conv1D)  (None, 512, 32)      8224        concatenate_31[0][0]             \n__________________________________________________________________________________________________\nconcatenate_32 (Concatenate)    (None, 512, 64)      0           training_task_final_layer[0][0]  \n                                                                 test_task_final_layer[0][0]      \n__________________________________________________________________________________________________\nflatten_8 (Flatten)             (None, 32768)        0           concatenate_32[0][0]             \n__________________________________________________________________________________________________\ndense_61 (Dense)                (None, 128)          4194432     flatten_8[0][0]                  \n__________________________________________________________________________________________________\ndense_62 (Dense)                (None, 256)          33024       dense_61[0][0]                   \n__________________________________________________________________________________________________\ndense_63 (Dense)                (None, 512)          131584      dense_62[0][0]                   \n__________________________________________________________________________________________________\npixel_predictor (Dense)         (None, 11)           5643        dense_63[0][0]                   \n==================================================================================================\nTotal params: 4,377,675\nTrainable params: 4,377,675\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# MULTI-Input-Output-CNN\n",
    "\n",
    "def create_model():\n",
    "    input_X1 = Input(shape=(None, 1))\n",
    "    input_X2 = Input(shape=(None, 1))\n",
    "    input_Y1 = Input(shape=(None, 1))\n",
    "    input_Y2 = Input(shape=(1024, 1))\n",
    "    x_1 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_X1)\n",
    "    x_2 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_X2)\n",
    "    x_sub = Subtract()([x_1, x_2])\n",
    "    x_fin = Conv1D(32, kernel_size=(4), strides=1, padding='same', name='training_task_final_layer')(x_sub)\n",
    "    \n",
    "    y_1 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_Y1)\n",
    "    y_1_pooling = MaxPooling1D(2)(y_1)\n",
    "    #y_1_flatten = Flatten()(y_1_pooling)\n",
    "    y_2 = Conv1D(filters=32, kernel_size=(4), strides=1, padding='same')(input_Y2)\n",
    "    y_2_pooling = MaxPooling1D(2)(y_2)\n",
    "    #y_2_flatten = Flatten()(y_2_pooling)\n",
    "    y_con = concatenate([y_1_pooling, y_2_pooling])\n",
    "    y_fin = Conv1D(32, kernel_size=(4), strides=1, padding='same', name='test_task_final_layer')(y_con)\n",
    "    \n",
    "    merge = concatenate([x_fin, y_fin])\n",
    "    #flat_layer = Flatten()(merge)\n",
    "\n",
    "    \n",
    "    #out_1 = Dense(11, activation='relu')(merge)\n",
    "    y_1_flatten = Flatten()(merge)\n",
    "    out_1 = Dense(128, activation='relu')(y_1_flatten)\n",
    "    out_1 = Dense(256, activation='relu')(out_1)\n",
    "    out_1 = Dense(512, activation='relu')(out_1)\n",
    "    out_1 = Dense(11, activation='softmax', name='pixel_predictor')(out_1)\n",
    "\n",
    "    #out_2 = Dense(64, activation='relu')(merge)\n",
    "    #y_1_flatten = Flatten()(merge)\n",
    "    #out_2 = Dense(128, activation='relu')(y_1_flatten)\n",
    "    #out_2 = Dense(1, activation='linear', name='shape_predictor')(out_2)\n",
    "    \n",
    "    model = Model(inputs=[input_X1, input_X2, input_Y1, input_Y2], outputs=[out_1])\n",
    "    \n",
    "    opt = Adam(lr=1e-3, decay=1e-3)\n",
    "    losses = {\n",
    "        \"pixel_predictor\": \"categorical_crossentropy\"\n",
    "        #\"shape_predictor\": \"mean_absolute_error\",\n",
    "    }\n",
    "\n",
    "    model.compile(loss=losses, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "multi_cnn = create_model()\n",
    "multi_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[9, 9]])"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "np.expand_dims(output_shape[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_61 to have 3 dimensions, but got array with shape (1, 45)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-76bb85db2b84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_list_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         np.expand_dims(input_list_4[0], 0)], \n\u001b[1;32m----> 5\u001b[1;33m         [np.expand_dims(output_pixel_all_iterations[0][0], 0)])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_61 to have 3 dimensions, but got array with shape (1, 45)"
     ]
    }
   ],
   "source": [
    "multi_cnn.fit([np.expand_dims(input_list_1[0], 0),\n",
    "        np.expand_dims(input_list_2[0], 0),\n",
    "        np.expand_dims(input_list_3[0], 0),\n",
    "        np.expand_dims(input_list_4[0], 0)], \n",
    "        [np.expand_dims(output_pixel_all_iterations[0][0], 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 45)\n(1, 405)\n(1, 9)\n(1, 1024)\n(1, 11)\n(1,)\n"
    }
   ],
   "source": [
    "for i in [np.expand_dims(input_list_1[0], 0),\n",
    "        np.expand_dims(input_list_2[0], 0),\n",
    "        np.expand_dims(input_list_3[0], 0),\n",
    "        np.expand_dims(input_list_4[0], 0),\n",
    "        np.expand_dims(output_pixel_all_iterations[0][0], 0),\n",
    "        np.expand_dims((output_shape[0][0]), 0)]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([9])"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "np.expand_dims((output_shape[0][0]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(output_pixel_all_iterations[0][0], axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python37764bittensorflowcondaa18ef89028c34345ba0acaf3baf91dbe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}